{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "3rdAssignmentCredit_Card_Fraud_Detection_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3pMtdOWM6VC"
      },
      "source": [
        "# Credit Card Fraud Detection::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iWhfpunM6Vd"
      },
      "source": [
        "Download dataset from this link:\n",
        "\n",
        "https://www.kaggle.com/mlg-ulb/creditcardfraud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzGnfD-KM6Vf"
      },
      "source": [
        "# Description about dataset::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtceYNBxM6Vh"
      },
      "source": [
        "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
        "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
        "\n",
        "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n",
        "\n",
        "\n",
        "### Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QMddR1yM6Vi"
      },
      "source": [
        "# WORKFLOW :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rN0RV-_M6Vi"
      },
      "source": [
        "1.Load Data\n",
        "\n",
        "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
        "\n",
        "3.Standardized the Input Variables. \n",
        "\n",
        "4.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
        "\n",
        "5.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
        "\n",
        "6.Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
        "\n",
        "7.Train the Model with Epochs (100).\n",
        "\n",
        "8.If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
        "\n",
        "9.Prediction should be > 92%\n",
        "10.Evaluation Step\n",
        "11Prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMCrVPGlM6Vj"
      },
      "source": [
        "# Task::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPOX_bVNM6Vj"
      },
      "source": [
        "## Identify fraudulent credit card transactions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLRH24RwM6Vj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef89ccb8-938d-4f33-b016-0ba4034e2888"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data=pd.read_csv('creditcard.csv')\n",
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       0\n",
              "V19       0\n",
              "V20       0\n",
              "V21       0\n",
              "V22       0\n",
              "V23       1\n",
              "V24       1\n",
              "V25       1\n",
              "V26       1\n",
              "V27       1\n",
              "V28       1\n",
              "Amount    1\n",
              "Class     1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kagTJHxcSTC"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj1URk0_aiko"
      },
      "source": [
        "#Using feature engineering library for Feature Engineering: #-U means most updated version\n",
        "!pip install -U feature-engine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AIpANwpZuOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b8df221-a854-42ce-d791-528bd6f31656"
      },
      "source": [
        "#filling missing value with mean of their feature\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "mean_imputer = MeanMedianImputer(imputation_method= 'mean', variables=['V23','V24','V25','V26','V27','V28','Amount','Class'])\n",
        "mean_imputer.fit(data)             #first we fit then we transform.\n",
        "mean_imputer.imputer_dict_\n",
        "data1 = mean_imputer.transform(data)\n",
        "data1.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       0\n",
              "V19       0\n",
              "V20       0\n",
              "V21       0\n",
              "V22       0\n",
              "V23       0\n",
              "V24       0\n",
              "V25       0\n",
              "V26       0\n",
              "V27       0\n",
              "V28       0\n",
              "Amount    0\n",
              "Class     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgzpW1VDM6Vk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "85167557-ab4c-408a-fca3-6dd048332a1b"
      },
      "source": [
        "#standardize\n",
        "from sklearn import preprocessing\n",
        "d = preprocessing.normalize(data1)\n",
        "names = ['Time','V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19','V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount','Class']\n",
        "scaled_df = pd.DataFrame(d, columns=names)\n",
        "scaled_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.009085</td>\n",
              "      <td>-0.000486</td>\n",
              "      <td>0.016946</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>-0.002260</td>\n",
              "      <td>0.003089</td>\n",
              "      <td>0.001601</td>\n",
              "      <td>0.000659</td>\n",
              "      <td>0.002431</td>\n",
              "      <td>0.000607</td>\n",
              "      <td>-0.003685</td>\n",
              "      <td>-0.004128</td>\n",
              "      <td>-0.006624</td>\n",
              "      <td>-0.002079</td>\n",
              "      <td>0.009809</td>\n",
              "      <td>-0.003143</td>\n",
              "      <td>0.001390</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>0.002699</td>\n",
              "      <td>0.001680</td>\n",
              "      <td>-0.000122</td>\n",
              "      <td>0.001856</td>\n",
              "      <td>-0.000738</td>\n",
              "      <td>0.000447</td>\n",
              "      <td>0.000859</td>\n",
              "      <td>-0.001264</td>\n",
              "      <td>0.000892</td>\n",
              "      <td>-0.000141</td>\n",
              "      <td>0.999658</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.314200</td>\n",
              "      <td>0.070163</td>\n",
              "      <td>0.043888</td>\n",
              "      <td>0.118143</td>\n",
              "      <td>0.015822</td>\n",
              "      <td>-0.021712</td>\n",
              "      <td>-0.020774</td>\n",
              "      <td>0.022435</td>\n",
              "      <td>-0.067336</td>\n",
              "      <td>-0.044018</td>\n",
              "      <td>0.425151</td>\n",
              "      <td>0.280820</td>\n",
              "      <td>0.128936</td>\n",
              "      <td>-0.037902</td>\n",
              "      <td>0.167547</td>\n",
              "      <td>0.122299</td>\n",
              "      <td>-0.030265</td>\n",
              "      <td>-0.048338</td>\n",
              "      <td>-0.038432</td>\n",
              "      <td>-0.018212</td>\n",
              "      <td>-0.059519</td>\n",
              "      <td>-0.168368</td>\n",
              "      <td>0.026702</td>\n",
              "      <td>-0.089591</td>\n",
              "      <td>0.044070</td>\n",
              "      <td>0.033189</td>\n",
              "      <td>-0.002368</td>\n",
              "      <td>0.003882</td>\n",
              "      <td>0.709144</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002641</td>\n",
              "      <td>-0.003587</td>\n",
              "      <td>-0.003539</td>\n",
              "      <td>0.004682</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>-0.001329</td>\n",
              "      <td>0.004754</td>\n",
              "      <td>0.002090</td>\n",
              "      <td>0.000654</td>\n",
              "      <td>-0.004000</td>\n",
              "      <td>0.000548</td>\n",
              "      <td>0.001649</td>\n",
              "      <td>0.000174</td>\n",
              "      <td>0.001894</td>\n",
              "      <td>-0.000438</td>\n",
              "      <td>0.006194</td>\n",
              "      <td>-0.007631</td>\n",
              "      <td>0.002931</td>\n",
              "      <td>-0.000320</td>\n",
              "      <td>-0.005973</td>\n",
              "      <td>0.001386</td>\n",
              "      <td>0.000655</td>\n",
              "      <td>0.002038</td>\n",
              "      <td>0.002401</td>\n",
              "      <td>-0.001820</td>\n",
              "      <td>-0.000865</td>\n",
              "      <td>-0.000367</td>\n",
              "      <td>-0.000146</td>\n",
              "      <td>-0.000158</td>\n",
              "      <td>0.999868</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.008092</td>\n",
              "      <td>-0.007819</td>\n",
              "      <td>-0.001499</td>\n",
              "      <td>0.014509</td>\n",
              "      <td>-0.006986</td>\n",
              "      <td>-0.000083</td>\n",
              "      <td>0.010092</td>\n",
              "      <td>0.001923</td>\n",
              "      <td>0.003054</td>\n",
              "      <td>-0.011224</td>\n",
              "      <td>-0.000445</td>\n",
              "      <td>-0.001833</td>\n",
              "      <td>0.001442</td>\n",
              "      <td>0.004109</td>\n",
              "      <td>-0.002330</td>\n",
              "      <td>-0.005109</td>\n",
              "      <td>-0.008575</td>\n",
              "      <td>-0.005536</td>\n",
              "      <td>0.015907</td>\n",
              "      <td>-0.009974</td>\n",
              "      <td>-0.001683</td>\n",
              "      <td>-0.000876</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>-0.001540</td>\n",
              "      <td>-0.009513</td>\n",
              "      <td>0.005239</td>\n",
              "      <td>-0.001796</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>0.000497</td>\n",
              "      <td>0.999366</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.028527</td>\n",
              "      <td>-0.016520</td>\n",
              "      <td>0.012520</td>\n",
              "      <td>0.022090</td>\n",
              "      <td>0.005749</td>\n",
              "      <td>-0.005808</td>\n",
              "      <td>0.001368</td>\n",
              "      <td>0.008457</td>\n",
              "      <td>-0.003859</td>\n",
              "      <td>0.011664</td>\n",
              "      <td>0.010741</td>\n",
              "      <td>-0.011737</td>\n",
              "      <td>0.007677</td>\n",
              "      <td>0.019196</td>\n",
              "      <td>-0.015970</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>-0.006439</td>\n",
              "      <td>-0.003381</td>\n",
              "      <td>-0.000545</td>\n",
              "      <td>0.011460</td>\n",
              "      <td>0.005827</td>\n",
              "      <td>-0.000135</td>\n",
              "      <td>0.011386</td>\n",
              "      <td>-0.001961</td>\n",
              "      <td>0.002015</td>\n",
              "      <td>-0.002938</td>\n",
              "      <td>0.007164</td>\n",
              "      <td>0.003130</td>\n",
              "      <td>0.003069</td>\n",
              "      <td>0.998299</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time        V1        V2        V3  ...       V27       V28    Amount  Class\n",
              "0  0.000000 -0.009085 -0.000486  0.016946  ...  0.000892 -0.000141  0.999658    0.0\n",
              "1  0.000000  0.314200  0.070163  0.043888  ... -0.002368  0.003882  0.709144    0.0\n",
              "2  0.002641 -0.003587 -0.003539  0.004682  ... -0.000146 -0.000158  0.999868    0.0\n",
              "3  0.008092 -0.007819 -0.001499  0.014509  ...  0.000508  0.000497  0.999366    0.0\n",
              "4  0.028527 -0.016520  0.012520  0.022090  ...  0.003130  0.003069  0.998299    0.0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keYadT0SM6Vk"
      },
      "source": [
        "#we are going to check correlation between independent and dependent variables such that the x variables with high correlation with y will be taken further for prediction of y.\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "corrmatrics = scaled_df.corr()\n",
        "highcorr_features =  corrmatrics.index\n",
        "plt.figure(figsize=(25,20))\n",
        "plot = sns.heatmap(scaled_df[highcorr_features].corr(),annot=True,cmap='RdYlGn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIUo1E4pyDTT",
        "outputId": "dce25763-2aa7-45f1-f25e-5bc02a5cc2f6"
      },
      "source": [
        "scaled_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(111004, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNZuTuOZM6Vk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b070f9a6-3801-46dd-9547-098ca36d0f32"
      },
      "source": [
        "x = scaled_df.loc[:,scaled_df.columns!='Class']\n",
        "y = scaled_df.loc[:,scaled_df.columns == 'Class']\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state =42)\n",
        "print(x_train.shape,y_train.shape)\n",
        "print(x_test.shape,y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(77702, 30) (77702, 1)\n",
            "(33302, 30) (33302, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVYL3mHivjUu",
        "outputId": "ad22695d-5e77-474c-a5a8-ce520760681e"
      },
      "source": [
        "x_train1,x_validation,y_train1,y_validation = train_test_split(x,y,test_size = 0.2,random_state =42)\n",
        "\n",
        "print(x_train1.shape,y_train1.shape)\n",
        "print(x_validation.shape,y_validation.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(88803, 30) (88803, 1)\n",
            "(22201, 30) (22201, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgCvrbzLM6Vl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "407b8cc7-56fb-4e67-cb47-76ef15788f94"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "network=models.Sequential()\n",
        "network.add(layers.Dense(10, activation='relu', input_shape=(30,)))\n",
        "network.add(layers.Dense(8,activation='relu'))\n",
        "network.add(layers.Dense(6,activation='relu'))\n",
        "network.add(layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "network.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "history = network.fit(x_train1, y_train1, epochs=100, batch_size=128,validation_data=(x_validation,y_validation))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "694/694 [==============================] - 2s 2ms/step - loss: 0.2497 - accuracy: 0.9981 - val_loss: 1.8713e-06 - val_accuracy: 0.9973\n",
            "Epoch 2/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.0768e-06 - accuracy: 0.9980 - val_loss: 1.8675e-06 - val_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.9726e-06 - accuracy: 0.9981 - val_loss: 1.8909e-06 - val_accuracy: 0.9973\n",
            "Epoch 4/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.5648e-06 - accuracy: 0.9980 - val_loss: 1.8932e-06 - val_accuracy: 0.9973\n",
            "Epoch 5/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.0685e-06 - accuracy: 0.9980 - val_loss: 1.9317e-06 - val_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.7015e-06 - accuracy: 0.9979 - val_loss: 1.9000e-06 - val_accuracy: 0.9973\n",
            "Epoch 7/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.0165e-06 - accuracy: 0.9978 - val_loss: 1.8771e-06 - val_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.6809e-06 - accuracy: 0.9979 - val_loss: 1.8985e-06 - val_accuracy: 0.9973\n",
            "Epoch 9/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.5653e-06 - accuracy: 0.9979 - val_loss: 1.8761e-06 - val_accuracy: 0.9973\n",
            "Epoch 10/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.5065e-06 - accuracy: 0.9983 - val_loss: 1.8686e-06 - val_accuracy: 0.9973\n",
            "Epoch 11/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.7687e-06 - accuracy: 0.9978 - val_loss: 1.9085e-06 - val_accuracy: 0.9973\n",
            "Epoch 12/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.5710e-06 - accuracy: 0.9981 - val_loss: 1.8686e-06 - val_accuracy: 0.9973\n",
            "Epoch 13/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.6214e-06 - accuracy: 0.9977 - val_loss: 1.8698e-06 - val_accuracy: 0.9973\n",
            "Epoch 14/100\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 3.0212e-06 - accuracy: 0.9978 - val_loss: 1.8758e-06 - val_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.6197e-06 - accuracy: 0.9979 - val_loss: 1.8875e-06 - val_accuracy: 0.9973\n",
            "Epoch 16/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.8262e-06 - accuracy: 0.9978 - val_loss: 1.8702e-06 - val_accuracy: 0.9973\n",
            "Epoch 17/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.9577e-06 - accuracy: 0.9980 - val_loss: 1.8850e-06 - val_accuracy: 0.9973\n",
            "Epoch 18/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.7607e-06 - accuracy: 0.9979 - val_loss: 1.8903e-06 - val_accuracy: 0.9973\n",
            "Epoch 19/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.2639e-06 - accuracy: 0.9978 - val_loss: 1.8674e-06 - val_accuracy: 0.9973\n",
            "Epoch 20/100\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 2.0450e-06 - accuracy: 0.9982 - val_loss: 1.8697e-06 - val_accuracy: 0.9973\n",
            "Epoch 21/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.5567e-06 - accuracy: 0.9979 - val_loss: 1.8762e-06 - val_accuracy: 0.9973\n",
            "Epoch 22/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.7918e-06 - accuracy: 0.9981 - val_loss: 1.8765e-06 - val_accuracy: 0.9973\n",
            "Epoch 23/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.5597e-06 - accuracy: 0.9979 - val_loss: 1.8924e-06 - val_accuracy: 0.9973\n",
            "Epoch 24/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.9242e-06 - accuracy: 0.9979 - val_loss: 1.8743e-06 - val_accuracy: 0.9973\n",
            "Epoch 25/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.0139e-06 - accuracy: 0.9982 - val_loss: 1.8736e-06 - val_accuracy: 0.9973\n",
            "Epoch 26/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.1131e-06 - accuracy: 0.9977 - val_loss: 1.8854e-06 - val_accuracy: 0.9973\n",
            "Epoch 27/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.6427e-06 - accuracy: 0.9980 - val_loss: 1.8736e-06 - val_accuracy: 0.9973\n",
            "Epoch 28/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.2928e-06 - accuracy: 0.9979 - val_loss: 1.8674e-06 - val_accuracy: 0.9973\n",
            "Epoch 29/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.4740e-06 - accuracy: 0.9977 - val_loss: 1.8731e-06 - val_accuracy: 0.9973\n",
            "Epoch 30/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.5326e-06 - accuracy: 0.9982 - val_loss: 1.8774e-06 - val_accuracy: 0.9973\n",
            "Epoch 31/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.6827e-06 - accuracy: 0.9981 - val_loss: 1.8855e-06 - val_accuracy: 0.9973\n",
            "Epoch 32/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.7321e-06 - accuracy: 0.9981 - val_loss: 1.8861e-06 - val_accuracy: 0.9973\n",
            "Epoch 33/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.3294e-06 - accuracy: 0.9981 - val_loss: 1.8809e-06 - val_accuracy: 0.9973\n",
            "Epoch 34/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.2536e-06 - accuracy: 0.9979 - val_loss: 1.8739e-06 - val_accuracy: 0.9973\n",
            "Epoch 35/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.9104e-06 - accuracy: 0.9980 - val_loss: 1.8811e-06 - val_accuracy: 0.9973\n",
            "Epoch 36/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.0083e-06 - accuracy: 0.9980 - val_loss: 1.9200e-06 - val_accuracy: 0.9973\n",
            "Epoch 37/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.8658e-06 - accuracy: 0.9978 - val_loss: 1.8772e-06 - val_accuracy: 0.9973\n",
            "Epoch 38/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.1604e-06 - accuracy: 0.9979 - val_loss: 1.8905e-06 - val_accuracy: 0.9973\n",
            "Epoch 39/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.5670e-06 - accuracy: 0.9980 - val_loss: 1.8750e-06 - val_accuracy: 0.9973\n",
            "Epoch 40/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.8987e-06 - accuracy: 0.9976 - val_loss: 1.9289e-06 - val_accuracy: 0.9973\n",
            "Epoch 41/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 3.6592e-06 - accuracy: 0.9978 - val_loss: 1.8933e-06 - val_accuracy: 0.9973\n",
            "Epoch 42/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.5789e-06 - accuracy: 0.9981 - val_loss: 1.8726e-06 - val_accuracy: 0.9973\n",
            "Epoch 43/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.8648e-06 - accuracy: 0.9979 - val_loss: 1.8907e-06 - val_accuracy: 0.9973\n",
            "Epoch 44/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.2919e-06 - accuracy: 0.9978 - val_loss: 1.8929e-06 - val_accuracy: 0.9973\n",
            "Epoch 45/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.8559e-06 - accuracy: 0.9979 - val_loss: 1.8952e-06 - val_accuracy: 0.9973\n",
            "Epoch 46/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.7294e-06 - accuracy: 0.9978 - val_loss: 1.8950e-06 - val_accuracy: 0.9973\n",
            "Epoch 47/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.7990e-06 - accuracy: 0.9979 - val_loss: 1.8842e-06 - val_accuracy: 0.9973\n",
            "Epoch 48/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.9379e-06 - accuracy: 0.9979 - val_loss: 1.8945e-06 - val_accuracy: 0.9973\n",
            "Epoch 49/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.8155e-06 - accuracy: 0.9978 - val_loss: 1.8737e-06 - val_accuracy: 0.9973\n",
            "Epoch 50/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.4057e-06 - accuracy: 0.9979 - val_loss: 1.8795e-06 - val_accuracy: 0.9973\n",
            "Epoch 51/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.5558e-06 - accuracy: 0.9978 - val_loss: 1.9015e-06 - val_accuracy: 0.9973\n",
            "Epoch 52/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.8473e-06 - accuracy: 0.9978 - val_loss: 1.8806e-06 - val_accuracy: 0.9973\n",
            "Epoch 53/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 3.3074e-06 - accuracy: 0.9981 - val_loss: 1.8992e-06 - val_accuracy: 0.9973\n",
            "Epoch 54/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.5820e-06 - accuracy: 0.9980 - val_loss: 1.8700e-06 - val_accuracy: 0.9973\n",
            "Epoch 55/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.9117e-06 - accuracy: 0.9980 - val_loss: 1.8670e-06 - val_accuracy: 0.9973\n",
            "Epoch 56/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.7040e-06 - accuracy: 0.9979 - val_loss: 1.8772e-06 - val_accuracy: 0.9973\n",
            "Epoch 57/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.6142e-06 - accuracy: 0.9983 - val_loss: 1.8841e-06 - val_accuracy: 0.9973\n",
            "Epoch 58/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.5510e-06 - accuracy: 0.9978 - val_loss: 1.8720e-06 - val_accuracy: 0.9973\n",
            "Epoch 59/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.5919e-06 - accuracy: 0.9981 - val_loss: 1.8690e-06 - val_accuracy: 0.9973\n",
            "Epoch 60/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.7951e-06 - accuracy: 0.9980 - val_loss: 1.8974e-06 - val_accuracy: 0.9973\n",
            "Epoch 61/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.9865e-06 - accuracy: 0.9981 - val_loss: 1.8821e-06 - val_accuracy: 0.9973\n",
            "Epoch 62/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.5042e-06 - accuracy: 0.9980 - val_loss: 1.9056e-06 - val_accuracy: 0.9973\n",
            "Epoch 63/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.4860e-06 - accuracy: 0.9978 - val_loss: 1.8768e-06 - val_accuracy: 0.9973\n",
            "Epoch 64/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.5353e-06 - accuracy: 0.9980 - val_loss: 1.8736e-06 - val_accuracy: 0.9973\n",
            "Epoch 65/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.6238e-06 - accuracy: 0.9979 - val_loss: 1.8702e-06 - val_accuracy: 0.9973\n",
            "Epoch 66/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.7030e-06 - accuracy: 0.9980 - val_loss: 1.8755e-06 - val_accuracy: 0.9973\n",
            "Epoch 67/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.1100e-06 - accuracy: 0.9981 - val_loss: 1.9125e-06 - val_accuracy: 0.9973\n",
            "Epoch 68/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.9061e-06 - accuracy: 0.9981 - val_loss: 1.8745e-06 - val_accuracy: 0.9973\n",
            "Epoch 69/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.7571e-06 - accuracy: 0.9981 - val_loss: 1.8960e-06 - val_accuracy: 0.9973\n",
            "Epoch 70/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.7273e-06 - accuracy: 0.9978 - val_loss: 1.8684e-06 - val_accuracy: 0.9973\n",
            "Epoch 71/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.8285e-06 - accuracy: 0.9979 - val_loss: 1.8814e-06 - val_accuracy: 0.9973\n",
            "Epoch 72/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.2657e-06 - accuracy: 0.9983 - val_loss: 1.8683e-06 - val_accuracy: 0.9973\n",
            "Epoch 73/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.4464e-06 - accuracy: 0.9981 - val_loss: 1.9006e-06 - val_accuracy: 0.9973\n",
            "Epoch 74/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.0852e-06 - accuracy: 0.9981 - val_loss: 1.8845e-06 - val_accuracy: 0.9973\n",
            "Epoch 75/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 4.3680e-06 - accuracy: 0.9980 - val_loss: 1.8749e-06 - val_accuracy: 0.9973\n",
            "Epoch 76/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.0651e-06 - accuracy: 0.9977 - val_loss: 1.9020e-06 - val_accuracy: 0.9973\n",
            "Epoch 77/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.3683e-06 - accuracy: 0.9981 - val_loss: 1.8858e-06 - val_accuracy: 0.9973\n",
            "Epoch 78/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.7042e-06 - accuracy: 0.9977 - val_loss: 1.8799e-06 - val_accuracy: 0.9973\n",
            "Epoch 79/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.2197e-06 - accuracy: 0.9983 - val_loss: 1.8712e-06 - val_accuracy: 0.9973\n",
            "Epoch 80/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.7726e-06 - accuracy: 0.9980 - val_loss: 1.8921e-06 - val_accuracy: 0.9973\n",
            "Epoch 81/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.6188e-06 - accuracy: 0.9980 - val_loss: 1.8743e-06 - val_accuracy: 0.9973\n",
            "Epoch 82/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.7335e-06 - accuracy: 0.9978 - val_loss: 1.8959e-06 - val_accuracy: 0.9973\n",
            "Epoch 83/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.5036e-06 - accuracy: 0.9979 - val_loss: 1.8820e-06 - val_accuracy: 0.9973\n",
            "Epoch 84/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.0783e-06 - accuracy: 0.9979 - val_loss: 1.8827e-06 - val_accuracy: 0.9973\n",
            "Epoch 85/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.1483e-06 - accuracy: 0.9976 - val_loss: 1.8914e-06 - val_accuracy: 0.9973\n",
            "Epoch 86/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.4639e-06 - accuracy: 0.9980 - val_loss: 1.8793e-06 - val_accuracy: 0.9973\n",
            "Epoch 87/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.7020e-06 - accuracy: 0.9978 - val_loss: 1.8811e-06 - val_accuracy: 0.9973\n",
            "Epoch 88/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.5206e-06 - accuracy: 0.9979 - val_loss: 1.8694e-06 - val_accuracy: 0.9973\n",
            "Epoch 89/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.1713e-06 - accuracy: 0.9979 - val_loss: 1.8700e-06 - val_accuracy: 0.9973\n",
            "Epoch 90/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.2403e-06 - accuracy: 0.9981 - val_loss: 1.8959e-06 - val_accuracy: 0.9973\n",
            "Epoch 91/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.3537e-06 - accuracy: 0.9978 - val_loss: 1.8895e-06 - val_accuracy: 0.9973\n",
            "Epoch 92/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.5420e-06 - accuracy: 0.9981 - val_loss: 1.8995e-06 - val_accuracy: 0.9973\n",
            "Epoch 93/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.6664e-06 - accuracy: 0.9978 - val_loss: 1.8853e-06 - val_accuracy: 0.9973\n",
            "Epoch 94/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.5388e-06 - accuracy: 0.9980 - val_loss: 1.8727e-06 - val_accuracy: 0.9973\n",
            "Epoch 95/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.8118e-06 - accuracy: 0.9981 - val_loss: 1.8751e-06 - val_accuracy: 0.9973\n",
            "Epoch 96/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.9640e-06 - accuracy: 0.9979 - val_loss: 1.8834e-06 - val_accuracy: 0.9973\n",
            "Epoch 97/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.9512e-06 - accuracy: 0.9978 - val_loss: 1.8792e-06 - val_accuracy: 0.9973\n",
            "Epoch 98/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.6572e-06 - accuracy: 0.9979 - val_loss: 1.8901e-06 - val_accuracy: 0.9973\n",
            "Epoch 99/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 1.7046e-06 - accuracy: 0.9979 - val_loss: 1.8886e-06 - val_accuracy: 0.9973\n",
            "Epoch 100/100\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 2.2525e-06 - accuracy: 0.9978 - val_loss: 1.8863e-06 - val_accuracy: 0.9973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YZm91dV6057"
      },
      "source": [
        "No overfitting in our model so we'll straight away run the model and predict test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubCOYT_GM6Vl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f2c24b-816a-43f7-e3b3-1d5e7ddbaaf8"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "network1=models.Sequential()\n",
        "network1.add(layers.Dense(10, activation='relu', input_shape=(30,)))\n",
        "network1.add(layers.Dense(8,activation='relu'))\n",
        "network1.add(layers.Dense(6,activation='relu'))\n",
        "network1.add(layers.Dense(1,activation='sigmoid'))\n",
        "network1.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "network1.fit(x_train, y_train, epochs=100, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 0.4098 - accuracy: 0.9866\n",
            "Epoch 2/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 3.0771e-06 - accuracy: 0.9979\n",
            "Epoch 3/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.7290e-06 - accuracy: 0.9982\n",
            "Epoch 4/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.8522e-06 - accuracy: 0.9982\n",
            "Epoch 5/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.1484e-06 - accuracy: 0.9981\n",
            "Epoch 6/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.8405e-06 - accuracy: 0.9981\n",
            "Epoch 7/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.6043e-06 - accuracy: 0.9982\n",
            "Epoch 8/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.5934e-06 - accuracy: 0.9981\n",
            "Epoch 9/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 3.0333e-06 - accuracy: 0.9982\n",
            "Epoch 10/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 3.1631e-06 - accuracy: 0.9983\n",
            "Epoch 11/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.9480e-06 - accuracy: 0.9979\n",
            "Epoch 12/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.5737e-06 - accuracy: 0.9982\n",
            "Epoch 13/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.7639e-06 - accuracy: 0.9982\n",
            "Epoch 14/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.9936e-06 - accuracy: 0.9980\n",
            "Epoch 15/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.2202e-06 - accuracy: 0.9979\n",
            "Epoch 16/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.0108e-06 - accuracy: 0.9979\n",
            "Epoch 17/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 3.7905e-06 - accuracy: 0.9979\n",
            "Epoch 18/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 3.2602e-06 - accuracy: 0.9980\n",
            "Epoch 19/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.6074e-06 - accuracy: 0.9979\n",
            "Epoch 20/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.5397e-06 - accuracy: 0.9982\n",
            "Epoch 21/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.5740e-06 - accuracy: 0.9980\n",
            "Epoch 22/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.9132e-06 - accuracy: 0.9978\n",
            "Epoch 23/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.6032e-06 - accuracy: 0.9982\n",
            "Epoch 24/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.6935e-06 - accuracy: 0.9978\n",
            "Epoch 25/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.8410e-06 - accuracy: 0.9979\n",
            "Epoch 26/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.2478e-06 - accuracy: 0.9980\n",
            "Epoch 27/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.5822e-06 - accuracy: 0.9983\n",
            "Epoch 28/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.5264e-06 - accuracy: 0.9979\n",
            "Epoch 29/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.5385e-06 - accuracy: 0.9983\n",
            "Epoch 30/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.0108e-06 - accuracy: 0.9980\n",
            "Epoch 31/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.1728e-06 - accuracy: 0.9980\n",
            "Epoch 32/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.5447e-06 - accuracy: 0.9978\n",
            "Epoch 33/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.2725e-06 - accuracy: 0.9978\n",
            "Epoch 34/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.4910e-06 - accuracy: 0.9981\n",
            "Epoch 35/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 3.5269e-06 - accuracy: 0.9981\n",
            "Epoch 36/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.6406e-06 - accuracy: 0.9981\n",
            "Epoch 37/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.7367e-06 - accuracy: 0.9983\n",
            "Epoch 38/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.4100e-06 - accuracy: 0.9981\n",
            "Epoch 39/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.1745e-06 - accuracy: 0.9980\n",
            "Epoch 40/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 4.1282e-06 - accuracy: 0.9981\n",
            "Epoch 41/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.2625e-06 - accuracy: 0.9980\n",
            "Epoch 42/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.6441e-06 - accuracy: 0.9980\n",
            "Epoch 43/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.3650e-06 - accuracy: 0.9980\n",
            "Epoch 44/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.3861e-06 - accuracy: 0.9981\n",
            "Epoch 45/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.8473e-06 - accuracy: 0.9978\n",
            "Epoch 46/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.9142e-06 - accuracy: 0.9980\n",
            "Epoch 47/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.5117e-06 - accuracy: 0.9981\n",
            "Epoch 48/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.0203e-06 - accuracy: 0.9981\n",
            "Epoch 49/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.4427e-06 - accuracy: 0.9983\n",
            "Epoch 50/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.1558e-06 - accuracy: 0.9979\n",
            "Epoch 51/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.8740e-06 - accuracy: 0.9981\n",
            "Epoch 52/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.0338e-06 - accuracy: 0.9983\n",
            "Epoch 53/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.6970e-06 - accuracy: 0.9981\n",
            "Epoch 54/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.7599e-06 - accuracy: 0.9980\n",
            "Epoch 55/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.4238e-06 - accuracy: 0.9982\n",
            "Epoch 56/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.1325e-06 - accuracy: 0.9983\n",
            "Epoch 57/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.7282e-06 - accuracy: 0.9980\n",
            "Epoch 58/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.2591e-06 - accuracy: 0.9980\n",
            "Epoch 59/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.9937e-06 - accuracy: 0.9982\n",
            "Epoch 60/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.3213e-06 - accuracy: 0.9981\n",
            "Epoch 61/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.5701e-06 - accuracy: 0.9980\n",
            "Epoch 62/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.8113e-06 - accuracy: 0.9980\n",
            "Epoch 63/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.3531e-06 - accuracy: 0.9979\n",
            "Epoch 64/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.7857e-06 - accuracy: 0.9981\n",
            "Epoch 65/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.2973e-06 - accuracy: 0.9980\n",
            "Epoch 66/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.7732e-06 - accuracy: 0.9981\n",
            "Epoch 67/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 3.1723e-06 - accuracy: 0.9978\n",
            "Epoch 68/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.0181e-06 - accuracy: 0.9979\n",
            "Epoch 69/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.5877e-06 - accuracy: 0.9981\n",
            "Epoch 70/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.9493e-06 - accuracy: 0.9978\n",
            "Epoch 71/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.6284e-06 - accuracy: 0.9982\n",
            "Epoch 72/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.7697e-06 - accuracy: 0.9981\n",
            "Epoch 73/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.4156e-06 - accuracy: 0.9981\n",
            "Epoch 74/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.4708e-06 - accuracy: 0.9978\n",
            "Epoch 75/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.4960e-06 - accuracy: 0.9981\n",
            "Epoch 76/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.3559e-06 - accuracy: 0.9982\n",
            "Epoch 77/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.5066e-06 - accuracy: 0.9981\n",
            "Epoch 78/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.5276e-06 - accuracy: 0.9980\n",
            "Epoch 79/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.0775e-06 - accuracy: 0.9981\n",
            "Epoch 80/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.4821e-06 - accuracy: 0.9981\n",
            "Epoch 81/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.9447e-06 - accuracy: 0.9980\n",
            "Epoch 82/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.6991e-06 - accuracy: 0.9977\n",
            "Epoch 83/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.8002e-06 - accuracy: 0.9982\n",
            "Epoch 84/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.0497e-06 - accuracy: 0.9980\n",
            "Epoch 85/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.6136e-06 - accuracy: 0.9982\n",
            "Epoch 86/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.9053e-06 - accuracy: 0.9981\n",
            "Epoch 87/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.7251e-06 - accuracy: 0.9979\n",
            "Epoch 88/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.4367e-06 - accuracy: 0.9981\n",
            "Epoch 89/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.4053e-06 - accuracy: 0.9979\n",
            "Epoch 90/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.7941e-06 - accuracy: 0.9981\n",
            "Epoch 91/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 3.4893e-06 - accuracy: 0.9980\n",
            "Epoch 92/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.8913e-06 - accuracy: 0.9980\n",
            "Epoch 93/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.7271e-06 - accuracy: 0.9981\n",
            "Epoch 94/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.7658e-06 - accuracy: 0.9983\n",
            "Epoch 95/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.7982e-06 - accuracy: 0.9979\n",
            "Epoch 96/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.8225e-06 - accuracy: 0.9979\n",
            "Epoch 97/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.1528e-06 - accuracy: 0.9981\n",
            "Epoch 98/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.8120e-06 - accuracy: 0.9981\n",
            "Epoch 99/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 2.0899e-06 - accuracy: 0.9981\n",
            "Epoch 100/100\n",
            "608/608 [==============================] - 1s 1ms/step - loss: 1.6237e-06 - accuracy: 0.9977\n",
            "1041/1041 [==============================] - 1s 983us/step - loss: 1.7148e-06 - accuracy: 0.9973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giwGVR8g8Fwy",
        "outputId": "969a2f26-3271-4ac7-a7e4-56e9c215bab7"
      },
      "source": [
        "#Evaluate:\n",
        "results = network1.evaluate(x_test,y_test) #we're getting the test accuracy as 99.7% which is greater than 92%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1041/1041 [==============================] - 1s 940us/step - loss: 1.7148e-06 - accuracy: 0.9973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXHIWlLYM6Vl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cfabcc7-0d72-4814-8f7f-b42ea2754d5d"
      },
      "source": [
        "#Prediction:\n",
        "network1.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.9369052e-08],\n",
              "       [7.9632443e-08],\n",
              "       [7.9627284e-08],\n",
              "       ...,\n",
              "       [7.7018150e-08],\n",
              "       [7.9592205e-08],\n",
              "       [7.9489496e-08]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2OyX_2BM6Vl"
      },
      "source": [
        "network1.predict(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT3-gRikM6Vl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz5oWOY7M6Vl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9VARw1GM6Vl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC0jUa3QM6Vl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p70y7K1BM6Vm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXIekKxXM6Vm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyC38-sKM6Vm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}